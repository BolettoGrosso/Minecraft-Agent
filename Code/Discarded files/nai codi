{"cells":[{"cell_type":"markdown","metadata":{"id":"BRYjtwRZGBOI"},"source":["### Install the required packages"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"35BJmtVpAP_n","outputId":"2bab39ab-c09c-4656-b09e-bc2cff2d798c","executionInfo":{"status":"ok","timestamp":1646225418487,"user_tz":-60,"elapsed":29154,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l\r\u001b[K     |▌                               | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |█                               | 20 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 30 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 40 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 51 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 61 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 81 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 92 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 102 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 112 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 122 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████                         | 133 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 143 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████                        | 153 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 163 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 174 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 184 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 194 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 204 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 215 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 225 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 235 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 245 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 256 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 266 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 276 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 286 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 296 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 307 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 317 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 327 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 337 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 348 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 358 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 368 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 378 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 389 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 399 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 409 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 419 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 430 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 440 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 450 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 460 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 471 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 481 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 491 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 501 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 512 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 522 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 532 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 542 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 552 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 563 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 573 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 583 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 593 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 604 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 614 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 616 kB 8.8 MB/s \n","\u001b[K     |████████████████████████████████| 234 kB 57.9 MB/s \n","\u001b[K     |████████████████████████████████| 6.4 MB 34.9 MB/s \n","\u001b[K     |████████████████████████████████| 120 kB 76.4 MB/s \n","\u001b[K     |████████████████████████████████| 77 kB 6.8 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 57.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.1 MB 61.0 MB/s \n","\u001b[K     |████████████████████████████████| 840 kB 68.0 MB/s \n","\u001b[K     |████████████████████████████████| 3.4 MB 52.7 MB/s \n","\u001b[K     |████████████████████████████████| 1.2 MB 59.5 MB/s \n","\u001b[K     |████████████████████████████████| 87 kB 7.7 MB/s \n","\u001b[K     |████████████████████████████████| 596 kB 70.9 MB/s \n","\u001b[K     |████████████████████████████████| 25.3 MB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 47.7 MB 1.5 MB/s \n","\u001b[K     |████████████████████████████████| 99 kB 11.1 MB/s \n","\u001b[K     |████████████████████████████████| 352 kB 70.9 MB/s \n","\u001b[K     |████████████████████████████████| 462 kB 76.2 MB/s \n","\u001b[K     |████████████████████████████████| 211 kB 74.1 MB/s \n","\u001b[?25h  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install -q tflite-model-maker\n","!pip install -q tflite-support"]},{"cell_type":"markdown","metadata":{"id":"prQ86DdtD317"},"source":["Import the required packages."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l4QQTXHHATDS"},"outputs":[],"source":["import numpy as np\n","import os\n","\n","from tflite_model_maker.config import ExportFormat, QuantizationConfig\n","from tflite_model_maker import model_spec\n","from tflite_model_maker import object_detector                          #Importacions basic\n","\n","from tflite_support import metadata                                     #Metadata que no sé ben bé què fa en aquest cas\n","\n","import tensorflow as tf\n","assert tf.__version__.startswith('2')                                   #Verifica la versió de tf emprada\n","\n","tf.get_logger().setLevel('ERROR')                                       #\n","from absl import logging\n","logging.set_verbosity(logging.ERROR)"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZ8qRl6KUAJE","executionInfo":{"status":"ok","timestamp":1646225456576,"user_tz":-60,"elapsed":32218,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}},"outputId":"216527a8-094f-408d-fc53-041f5899e9ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"Yxh3KInCFeB-"},"source":["## Train the object detection model\n","\n","### Step 1: Load the dataset\n","\n","* Images in `train_data` is used to train the custom object detection model.\n","* Images in `val_data` is used to check if the model can generalize well to new images that it hasn't seen before."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiAahdsQAdT7"},"outputs":[],"source":["train_data = object_detector.DataLoader.from_pascal_voc(\n","    '/content/drive/My Drive/TDR/screenshots/train',\n","    '/content/drive/My Drive/TDR/screenshots/train',\n","    ['slime']\n",")\n","\n","val_data = object_detector.DataLoader.from_pascal_voc(\n","    '/content/drive/My Drive/TDR/screenshots/validate',\n","    '/content/drive/My Drive/TDR/screenshots/validate',\n","    ['slime']\n",")"]},{"cell_type":"markdown","metadata":{"id":"UNRhB8N7GHXj"},"source":["### Step 2: Select a model architecture\n","\n","EfficientDet-Lite[0-4] are a family of mobile/IoT-friendly object detection models derived from the [EfficientDet](https://arxiv.org/abs/1911.09070) architecture.\n","\n","Here is the performance of each EfficientDet-Lite models compared to each others.\n","\n","| Model architecture | Size(MB)* | Latency(ms)** | Average Precision*** |\n","|--------------------|-----------|---------------|----------------------|\n","| EfficientDet-Lite0 | 4.4       | 146           | 25.69%               |\n","| EfficientDet-Lite1 | 5.8       | 259           | 30.55%               |\n","| EfficientDet-Lite2 | 7.2       | 396           | 33.97%               |\n","| EfficientDet-Lite3 | 11.4      | 716           | 37.70%               |\n","| EfficientDet-Lite4 | 19.9      | 1886          | 41.96%               |\n","\n","<i> * Size of the integer quantized models. <br/>\n","** Latency measured on Raspberry Pi 4 using 4 threads on CPU. <br/>\n","*** Average Precision is the mAP (mean Average Precision) on the COCO 2017 validation dataset.\n","</i>\n","\n","In this notebook, we use EfficientDet-Lite0 to train our model. You can choose other model architectures depending on whether speed or accuracy is more important to you."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GZOojrDHAY1J"},"outputs":[],"source":["spec = model_spec.get('efficientdet_lite0')"]},{"cell_type":"markdown","metadata":{"id":"5aeDU4mIM4ft"},"source":["### Step 3: Train the TensorFlow model with the training data.\n","\n","* Set `epochs = 20`, which means it will go through the training dataset 20 times. You can look at the validation accuracy during training and stop when you see validation loss (`val_loss`) stop decreasing to avoid overfitting.\n","* Set `batch_size = 4` here so you will see that it takes 15 steps to go through the 62 images in the training dataset.\n","* Set `train_whole_model=True` to fine-tune the whole model instead of just training the head layer to improve accuracy. The trade-off is that it may take longer to train the model."]},{"cell_type":"code","source":["len(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QG4jEJYtTkWO","executionInfo":{"status":"ok","timestamp":1646225497289,"user_tz":-60,"elapsed":29,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}},"outputId":"109f01b2-479f-42be-a2c8-d91e0daeb98e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["31"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_MClfpsJAfda","outputId":"36daf364-c6ed-49fd-f072-1342aa07f144","executionInfo":{"status":"ok","timestamp":1646225928119,"user_tz":-60,"elapsed":430854,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","7/7 [==============================] - 51s 3s/step - det_loss: 1.9700 - cls_loss: 1.1195 - box_loss: 0.0170 - reg_l2_loss: 0.0630 - loss: 2.0330 - learning_rate: 0.0066 - gradient_norm: 2.0256 - val_det_loss: 1.7707 - val_cls_loss: 1.0956 - val_box_loss: 0.0135 - val_reg_l2_loss: 0.0630 - val_loss: 1.8337\n","Epoch 2/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 1.9596 - cls_loss: 1.0836 - box_loss: 0.0175 - reg_l2_loss: 0.0630 - loss: 2.0226 - learning_rate: 0.0049 - gradient_norm: 2.0494 - val_det_loss: 1.6872 - val_cls_loss: 1.0561 - val_box_loss: 0.0126 - val_reg_l2_loss: 0.0630 - val_loss: 1.7502\n","Epoch 3/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 1.8893 - cls_loss: 1.0321 - box_loss: 0.0171 - reg_l2_loss: 0.0630 - loss: 1.9523 - learning_rate: 0.0048 - gradient_norm: 2.7496 - val_det_loss: 1.5721 - val_cls_loss: 0.9798 - val_box_loss: 0.0118 - val_reg_l2_loss: 0.0630 - val_loss: 1.6351\n","Epoch 4/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 1.5879 - cls_loss: 0.9083 - box_loss: 0.0136 - reg_l2_loss: 0.0630 - loss: 1.6509 - learning_rate: 0.0046 - gradient_norm: 2.1609 - val_det_loss: 1.3319 - val_cls_loss: 0.7924 - val_box_loss: 0.0108 - val_reg_l2_loss: 0.0630 - val_loss: 1.3949\n","Epoch 5/20\n","7/7 [==============================] - 26s 4s/step - det_loss: 1.3376 - cls_loss: 0.6976 - box_loss: 0.0128 - reg_l2_loss: 0.0630 - loss: 1.4006 - learning_rate: 0.0043 - gradient_norm: 2.8117 - val_det_loss: 1.3429 - val_cls_loss: 0.8519 - val_box_loss: 0.0098 - val_reg_l2_loss: 0.0630 - val_loss: 1.4060\n","Epoch 6/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 1.1095 - cls_loss: 0.5512 - box_loss: 0.0112 - reg_l2_loss: 0.0630 - loss: 1.1725 - learning_rate: 0.0040 - gradient_norm: 3.2128 - val_det_loss: 1.8678 - val_cls_loss: 1.4010 - val_box_loss: 0.0093 - val_reg_l2_loss: 0.0630 - val_loss: 1.9308\n","Epoch 7/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 1.0701 - cls_loss: 0.5234 - box_loss: 0.0109 - reg_l2_loss: 0.0630 - loss: 1.1332 - learning_rate: 0.0037 - gradient_norm: 3.5799 - val_det_loss: 1.2489 - val_cls_loss: 0.7979 - val_box_loss: 0.0090 - val_reg_l2_loss: 0.0630 - val_loss: 1.3119\n","Epoch 8/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 1.0625 - cls_loss: 0.4749 - box_loss: 0.0118 - reg_l2_loss: 0.0630 - loss: 1.1255 - learning_rate: 0.0033 - gradient_norm: 2.7304 - val_det_loss: 1.1058 - val_cls_loss: 0.6771 - val_box_loss: 0.0086 - val_reg_l2_loss: 0.0630 - val_loss: 1.1689\n","Epoch 9/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 1.0159 - cls_loss: 0.4375 - box_loss: 0.0116 - reg_l2_loss: 0.0630 - loss: 1.0789 - learning_rate: 0.0029 - gradient_norm: 2.5084 - val_det_loss: 0.9360 - val_cls_loss: 0.5239 - val_box_loss: 0.0082 - val_reg_l2_loss: 0.0630 - val_loss: 0.9990\n","Epoch 10/20\n","7/7 [==============================] - 17s 3s/step - det_loss: 0.9168 - cls_loss: 0.3935 - box_loss: 0.0105 - reg_l2_loss: 0.0630 - loss: 0.9798 - learning_rate: 0.0025 - gradient_norm: 2.5687 - val_det_loss: 0.9191 - val_cls_loss: 0.5074 - val_box_loss: 0.0082 - val_reg_l2_loss: 0.0630 - val_loss: 0.9822\n","Epoch 11/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.8568 - cls_loss: 0.3761 - box_loss: 0.0096 - reg_l2_loss: 0.0630 - loss: 0.9199 - learning_rate: 0.0021 - gradient_norm: 2.5412 - val_det_loss: 0.8917 - val_cls_loss: 0.4860 - val_box_loss: 0.0081 - val_reg_l2_loss: 0.0630 - val_loss: 0.9547\n","Epoch 12/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.8134 - cls_loss: 0.3512 - box_loss: 0.0092 - reg_l2_loss: 0.0630 - loss: 0.8764 - learning_rate: 0.0017 - gradient_norm: 2.3821 - val_det_loss: 0.8362 - val_cls_loss: 0.4476 - val_box_loss: 0.0078 - val_reg_l2_loss: 0.0630 - val_loss: 0.8993\n","Epoch 13/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.8216 - cls_loss: 0.3589 - box_loss: 0.0093 - reg_l2_loss: 0.0630 - loss: 0.8847 - learning_rate: 0.0013 - gradient_norm: 2.2524 - val_det_loss: 0.7843 - val_cls_loss: 0.4130 - val_box_loss: 0.0074 - val_reg_l2_loss: 0.0630 - val_loss: 0.8473\n","Epoch 14/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.8580 - cls_loss: 0.3554 - box_loss: 0.0101 - reg_l2_loss: 0.0630 - loss: 0.9211 - learning_rate: 9.7221e-04 - gradient_norm: 3.1795 - val_det_loss: 0.7487 - val_cls_loss: 0.3877 - val_box_loss: 0.0072 - val_reg_l2_loss: 0.0630 - val_loss: 0.8118\n","Epoch 15/20\n","7/7 [==============================] - 17s 3s/step - det_loss: 0.8441 - cls_loss: 0.3379 - box_loss: 0.0101 - reg_l2_loss: 0.0630 - loss: 0.9072 - learning_rate: 6.6799e-04 - gradient_norm: 2.3407 - val_det_loss: 0.7152 - val_cls_loss: 0.3641 - val_box_loss: 0.0070 - val_reg_l2_loss: 0.0630 - val_loss: 0.7783\n","Epoch 16/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.8033 - cls_loss: 0.3644 - box_loss: 0.0088 - reg_l2_loss: 0.0630 - loss: 0.8663 - learning_rate: 4.1374e-04 - gradient_norm: 2.5198 - val_det_loss: 0.6900 - val_cls_loss: 0.3444 - val_box_loss: 0.0069 - val_reg_l2_loss: 0.0630 - val_loss: 0.7530\n","Epoch 17/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.7277 - cls_loss: 0.3405 - box_loss: 0.0077 - reg_l2_loss: 0.0630 - loss: 0.7908 - learning_rate: 2.1640e-04 - gradient_norm: 2.4296 - val_det_loss: 0.6757 - val_cls_loss: 0.3331 - val_box_loss: 0.0069 - val_reg_l2_loss: 0.0630 - val_loss: 0.7387\n","Epoch 18/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.7282 - cls_loss: 0.3186 - box_loss: 0.0082 - reg_l2_loss: 0.0630 - loss: 0.7913 - learning_rate: 8.1348e-05 - gradient_norm: 2.2777 - val_det_loss: 0.6682 - val_cls_loss: 0.3273 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0630 - val_loss: 0.7313\n","Epoch 19/20\n","7/7 [==============================] - 15s 2s/step - det_loss: 0.9369 - cls_loss: 0.3836 - box_loss: 0.0111 - reg_l2_loss: 0.0630 - loss: 0.9999 - learning_rate: 1.2273e-05 - gradient_norm: 2.8247 - val_det_loss: 0.6633 - val_cls_loss: 0.3233 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0630 - val_loss: 0.7263\n","Epoch 20/20\n","7/7 [==============================] - 17s 3s/step - det_loss: 0.8269 - cls_loss: 0.3665 - box_loss: 0.0092 - reg_l2_loss: 0.0630 - loss: 0.8900 - learning_rate: 1.1057e-05 - gradient_norm: 3.0236 - val_det_loss: 0.6610 - val_cls_loss: 0.3209 - val_box_loss: 0.0068 - val_reg_l2_loss: 0.0630 - val_loss: 0.7240\n"]}],"source":["model = object_detector.create(train_data, model_spec=spec, batch_size=4, train_whole_model=True, epochs=20, validation_data=val_data)"]},{"cell_type":"markdown","metadata":{"id":"KB4hKeerMmh4"},"source":["### Step 4. Evaluate the model with the validation data.\n","\n","After training the object detection model using the images in the training dataset, use the 10 images in the validation dataset to evaluate how the model performs against new data it has never seen before.\n","\n","As the default batch size is 64, it will take 1 step to go through the 10 images in the validation dataset.\n","\n","The evaluation metrics are same as [COCO](https://cocodataset.org/#detection-eval)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OUqEpcYwAg8L","outputId":"ade333e0-9699-4381-c83e-ada6569421d2","executionInfo":{"status":"ok","timestamp":1646225947111,"user_tz":-60,"elapsed":6494,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\r1/1 [==============================] - 5s 5s/step\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["{'AP': 0.46658415,\n"," 'AP50': 0.8589109,\n"," 'AP75': 0.47744775,\n"," 'AP_/slime': 0.46658415,\n"," 'APl': 0.497401,\n"," 'APm': 0.45445544,\n"," 'APs': -1.0,\n"," 'ARl': 0.55,\n"," 'ARm': 0.45,\n"," 'ARmax1': 0.39166668,\n"," 'ARmax10': 0.53333336,\n"," 'ARmax100': 0.53333336,\n"," 'ARs': -1.0}"]},"metadata":{},"execution_count":10}],"source":["model.evaluate(val_data)"]},{"cell_type":"code","source":["model.predict()"],"metadata":{"id":"9FRiMxXPxDMT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NARVYk9rGLIl"},"source":["### Step 5: Export as a TensorFlow Lite model.\n","\n","Export the trained object detection model to the TensorFlow Lite format by specifying which folder you want to export the quantized model to. The default post-training quantization technique is [full integer quantization](https://www.tensorflow.org/lite/performance/post_training_integer_quant). This allows the TensorFlow Lite model to be smaller, run faster on Raspberry Pi CPU and also compatible with the Google Coral EdgeTPU."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_u3eFxoBAiqE"},"outputs":[],"source":["model.export(export_dir='.', tflite_filename='nai')"]},{"cell_type":"markdown","metadata":{"id":"JZcBmEigOCO3"},"source":["### Step 6:  Evaluate the TensorFlow Lite model.\n","\n","Several factors can affect the model accuracy when exporting to TFLite:\n","* [Quantization](https://www.tensorflow.org/lite/performance/model_optimization) helps shrinking the model size by 4 times at the expense of some accuracy drop.\n","* The original TensorFlow model uses per-class [non-max supression (NMS)](https://www.coursera.org/lecture/convolutional-neural-networks/non-max-suppression-dvrjH) for post-processing, while the TFLite model uses global NMS that's much faster but less accurate.\n","Keras outputs maximum 100 detections while tflite outputs maximum 25 detections.\n","\n","Therefore you'll have to evaluate the exported TFLite model and compare its accuracy with the original TensorFlow model."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jbl8z9_wBPlr","outputId":"aa5fef12-1d39-482f-85d1-f1fd63132d30","executionInfo":{"status":"ok","timestamp":1646226075526,"user_tz":-60,"elapsed":42243,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["9/9 [==============================] - 26s 3s/step\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["{'AP': 0.4370627,\n"," 'AP50': 0.80165017,\n"," 'AP75': 0.49240923,\n"," 'AP_/slime': 0.4370627,\n"," 'APl': 0.46940693,\n"," 'APm': 0.4039604,\n"," 'APs': -1.0,\n"," 'ARl': 0.49,\n"," 'ARm': 0.4,\n"," 'ARmax1': 0.36666667,\n"," 'ARmax10': 0.475,\n"," 'ARmax100': 0.475,\n"," 'ARs': -1.0}"]},"metadata":{},"execution_count":13}],"source":["model.evaluate_tflite('nai', val_data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v7zgUkdOUUnD"},"outputs":[],"source":["# Download the TFLite model to your local computer.\n","from google.colab import files\n","files.download('android.tflite')"]},{"cell_type":"code","source":[""],"metadata":{"id":"GZblBECMyuyJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["##Coses rares"],"metadata":{"id":"JIJS2rn0yu0s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall opencv-python-headless==4.5.5.62"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3BmwXLYs0A8c","executionInfo":{"status":"ok","timestamp":1646227672421,"user_tz":-60,"elapsed":22235,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}},"outputId":"42efb7c8-cd36-44a9-e870-69c3c775b5ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: opencv-python-headless 4.5.5.62\n","Uninstalling opencv-python-headless-4.5.5.62:\n","  Would remove:\n","    /usr/local/lib/python3.7/dist-packages/cv2/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless-4.5.5.62.dist-info/*\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavcodec-64ac49e1.so.58.91.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavformat-4b79e479.so.58.45.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libavutil-805734e8.so.56.51.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libbz2-a273e504.so.1.0.6\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libcrypto-018b8c17.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libgfortran-91cc3cb1.so.3.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libopenblas-r0-f650aae0.3.3.so\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libpng15-ce838cd1.so.15.13.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libquadmath-96973f99.so.0.0.0\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libssl-6082116c.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswresample-83ce3247.so.3.7.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libswscale-7e960168.so.5.7.100\n","    /usr/local/lib/python3.7/dist-packages/opencv_python_headless.libs/libvpx-392cd848.so.6.4.0\n","  Would not remove (might be manually added):\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtCore-bbdab771.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtGui-903938cd.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libQtTest-1183da5d.so.4.8.7\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavcodec-3cdd3bd4.so.58.62.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavformat-69a63b50.so.58.35.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libavutil-8e8979a8.so.56.36.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libbz2-7225278b.so.1.0.3\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libcrypto-a25ff511.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libssl-fdf0b66c.so.1.1\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswresample-c6b3bbb9.so.3.6.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libswscale-2d19f7d1.so.5.6.100\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libvpx-c887ea55.so.6.1.0\n","    /usr/local/lib/python3.7/dist-packages/cv2/.libs/libz-a147dcb0.so.1.2.3\n","    /usr/local/lib/python3.7/dist-packages/cv2/cv2.cpython-37m-x86_64-linux-gnu.so\n","Proceed (y/n)? y\n","  Successfully uninstalled opencv-python-headless-4.5.5.62\n"]}]},{"cell_type":"code","source":["!pip install opencv-python-headless==4.5.2.52"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-DTKzHC60DeH","executionInfo":{"status":"ok","timestamp":1646227684862,"user_tz":-60,"elapsed":9053,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}},"outputId":"c99ac090-715f-49e0-9bb5-1d8e1c95b956"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting opencv-python-headless==4.5.2.52\n","  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n","\u001b[K     |████████████████████████████████| 38.2 MB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.5)\n","Installing collected packages: opencv-python-headless\n","Successfully installed opencv-python-headless-4.5.2.52\n"]}]},{"cell_type":"code","source":["import cv2 as cv \n","import numpy as np\n","import matplotlib\n","%matplotlib inline\n","import tensorflow as tf\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as viz_utils\n","from object_detection.builders import model_builder\n","from object_detection.utils import config_util"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":374},"id":"6rfOS8f3yu2d","executionInfo":{"status":"error","timestamp":1646227787152,"user_tz":-60,"elapsed":288,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}},"outputId":"4d0ae04d-b8a6-435f-af58-b375958bf1b2"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-a7b71725d824>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvisualization_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mviz_utils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'object_detection'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":166},"id":"2PIQG0nr0UTP","executionInfo":{"status":"error","timestamp":1646227723282,"user_tz":-60,"elapsed":18,"user":{"displayName":"Tomàs Gea Solà","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUqGnlXuUsGI1hqTx9OxToQPaKWmaqkE6Zc2u3xQ=s64","userId":"13685799614759478584"}},"outputId":"c9a8e2ce-1627-4e02-c202-eb44c3d01da6"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-2a68b5a8bd58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategory_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_category_index_from_labelmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LABELMAP'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'label_map_util' is not defined"]}]},{"cell_type":"code","source":["category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"],"metadata":{"id":"cXAnPhH-y0GA"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"nai codi","provenance":[{"file_id":"https://github.com/khanhlvg/tflite_raspberry_pi/blob/main/object_detection/Train_custom_model_tutorial.ipynb","timestamp":1646218443304}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}